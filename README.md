# RAG Assistant (Groq + ChromaDB)
A Safety-Aware Document-Grounded Chatbot using Groq and ChromaDB
![RAG Cover](images/rag_cover.png)

ğŸ“Œ Project Description

This project implements a Retrieval-Augmented Generation (RAG) assistant that combines vector-based document retrieval with large language model (LLM) inference to produce grounded, context-aware responses.

Unlike standalone LLMs that may hallucinate, this system retrieves relevant information from an external document corpus before generating answers, improving factual accuracy, transparency, and reliability.
The system also incorporates basic safety guardrails to support responsible usage.

ğŸ” Project Overview

The RAG assistant follows a modular pipeline:
1.Document ingestion and preprocessing
2.Dense vector embedding and persistent storage
3.Safety-aware query handling
4.Similarity-based retrieval
5.Context-conditioned response generation
This design makes the system suitable for academic, research, and domain-specific applications.

ğŸ“‚ Project Structure
project/
â”œâ”€â”€ LICENSE
â”œâ”€â”€ app.py                  # Main application entry point
â”œâ”€â”€ vectordb.py             # Vector database (ChromaDB) wrapper
â”œâ”€â”€ safety.py               # Safety and content guardrails
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ images/                 # Visual assets
â”‚   â”œâ”€â”€ rag_cover.png
â”‚   â”œâ”€â”€ rag_architecture.png
â”‚   â”œâ”€â”€ methodology_flow.png
â”œâ”€â”€ data/                   # Input .txt documents
â””â”€â”€ rag_clients_db/         # Persistent ChromaDB storage

ğŸ—ï¸ System Architecture
![Architecture](images/rag_architecture.png)

ğŸ§  Methodology
![Workflow](images/methodology_flow.png)

ğŸ” Safety & Ethical Considerations
To ensure responsible usage, the system includes:
 -Rule-based filtering for unsafe or restricted queries
 -Conservative fallback responses when information is unavailable
 -Prompt instructions to avoid hallucination
These safeguards provide a foundation for future enhancements such as neural moderation and audit logging.

ğŸ›  Prerequisites
 -Python 3.10 or higher
 -Groq API key
 -Basic Python knowledge
 -Sufficient memory for embeddings

ğŸš€ Step-by-Step Usage Guide
1ï¸âƒ£ Clone the Repository
git clone <repository-url>
cd project
2ï¸âƒ£ Create a Virtual Environment
python -m venv .venv
source .venv/bin/activate     # Linux/macOS
.venv\Scripts\Activate.ps1    # Windows
3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
4ï¸âƒ£ Configure Environment Variables
GROQ_API_KEY=your_api_key_here
5ï¸âƒ£ Add Documents

Place non-empty .txt files inside the data/ directory.

6ï¸âƒ£ Run the Application
python app.py

ğŸ“Œ Applications
 - Domain-specific question answering
 - Academic research assistants
 - Enterprise knowledge bases
 - Documentation chatbots
 - Controlled AI assistants

âš ï¸ Limitations
 - Safety filtering is rule-based and limited
 - No explicit source citation in responses
 - Response quality depends on document coverage
 - No multi-hop reasoning across documents

ğŸ”® Future Enhancements
 - Neural content moderation
 - Citation-aware responses
 - Multi-document reasoning
 - Web-based user interface
 - Quantitative evaluation benchmarks

ğŸ“„ License & Usage

This project is intended for educational and research purposes.
Users are responsible for ensuring ethical, legal, and compliant usage in real-world deployments.
